# Hybrid FastAPI + FastMCP + Event Sourcing - DETAILED Implementation Checklist

**CRITICAL FINDINGS from Codebase Analysis**:
- âš ï¸ Existing event system in `src/orchestrator/events.py` (simple, no vector clocks)
- âš ï¸ Streaming already exists in `src/orchestrator/streaming.py` (AsyncIterator pattern)
- âš ï¸ Global state dictionaries NOT thread-safe (StateManager, InterventionManager)
- âš ï¸ AsyncLogger file writes NOT atomic (race conditions)
- âš ï¸ TestRunner uses subprocess.run (blocks event loop, not truly async)

---

## Phase 1: Event Store Foundation ğŸ—ï¸

### 1.1 Core Event Types

**File**: `src/events/__init__.py` (â‰¤20 lines)
- [ ] Create module structure
- [ ] Export: Event, EventType, EventStore, VectorClock, StateProjection, EventOrdering

**File**: `src/events/event_types.py` (â‰¤100 lines)
- [ ] Define `EventType` enum with 18 types

**INTEGRATION NOTE**: Must merge with existing `src/orchestrator/events.py`:
- Existing: TASK_STARTED, PLANNING_COMPLETE, MODULE_STARTED, MODULE_ITERATION, TASK_COMPLETE
- New additions: CODE_GENERATED, CORRECTION_STARTED, CORRECTION_COMPLETED, BUG_REPORT_RECEIVED, TEST_STARTED, TEST_PASSED, TEST_FAILED

**File**: `src/events/event.py` (â‰¤100 lines)
- [ ] Define `Event` dataclass (frozen=True)
- [ ] Add `__post_init__` validation
- [ ] Add `to_dict()` method

**PASSING CRITERIA**:
- âœ… Event is immutable (frozen=True enforced)
- âœ… event_id is valid UUID format
- âœ… task_id is non-empty string
- âœ… timestamp is valid ISO 8601
- âœ… sequence_number is positive integer
- âœ… code_version â‰¥ 0

**FAILING CRITERIA**:
- âŒ Event modified after creation (raises FrozenInstanceError)
- âŒ event_id is None or empty
- âŒ task_id is None, empty, or non-string
- âŒ vector_clock is not Dict[str, int]
- âŒ data contains non-serializable objects

**EDGE CASES**:
1. Empty vector_clock {} - should be valid
2. causation_id = None - valid for root events
3. data = {} - valid empty metadata
4. Large data dict (>1MB) - should handle
5. Unicode in task_id - should sanitize
6. Negative code_version - should reject
7. Future timestamp - should reject
8. sequence_number = 0 - should allow (initial event)

---

### 1.2 Vector Clock Implementation

**File**: `src/events/vector_clock.py` (â‰¤100 lines)
- [ ] Implement `VectorClock` class

**PASSING CRITERIA**:
- âœ… tick() increments process_id counter by exactly 1
- âœ… merge() takes max of each process value
- âœ… happens_before() correctly identifies causal precedence
- âœ… concurrent() returns True when no causal relationship exists
- âœ… Empty clocks handled (return False for happens_before)

**FAILING CRITERIA**:
- âŒ tick() increments by â‰ 1
- âŒ merge() doesn't take max (takes min, sum, etc.)
- âŒ happens_before() false positive (clock1 || clock2 returns True)
- âŒ happens_before() false negative (clock1 < clock2 returns False)
- âŒ concurrent() returns True for causal events

**EDGE CASES**:
1. **Empty clocks**: {} vs {} - should be concurrent
2. **Single process**: {"p1": 5} vs {"p1": 3} - should be happens_before
3. **Disjoint processes**: {"p1": 1} vs {"p2": 1} - should be concurrent
4. **Subset relation**: {"p1": 1} vs {"p1": 1, "p2": 1} - happens_before
5. **Equal clocks**: {"p1": 5, "p2": 3} vs {"p1": 5, "p2": 3} - concurrent (not <)
6. **Negative values**: {"p1": -1} - should reject or sanitize
7. **Process ID collision**: Same process_id from different sources
8. **Very large values**: {"p1": 2^63} - integer overflow check

---

### 1.3 Event Store

**File**: `src/events/event_store.py` (â‰¤100 lines)
- [ ] Implement `EventStore` class

**PASSING CRITERIA**:
- âœ… append() is thread-safe (asyncio.Lock)
- âœ… Sequence numbers increment by exactly 1 with no gaps
- âœ… Persistence succeeds and file is readable
- âœ… get_events() filters by task_id correctly
- âœ… get_events(after_sequence=N) returns only events > N
- âœ… Concurrent appends don't corrupt sequence

**FAILING CRITERIA**:
- âŒ Sequence number gaps exist (e.g., 1, 2, 4...)
- âŒ Sequence numbers repeat (e.g., 1, 2, 2, 3)
- âŒ Concurrent appends cause race condition
- âŒ Persistence fails silently
- âŒ get_events() returns events from wrong task
- âŒ File corruption on interrupted write

**EDGE CASES**:
1. **Concurrent append from 10 tasks** - all should get unique sequences
2. **Disk full during persist** - should handle gracefully
3. **File permissions** - should handle permission errors
4. **Large event data** (10MB) - should handle or reject with clear error
5. **Very long task_id** (1000 chars) - should handle or reject
6. **Special chars in task_id** (`/`, `\`, null) - should sanitize
7. **append() interrupted mid-write** - should not corrupt store
8. **get_events() with negative after_sequence** - should handle
9. **Empty store** - get_events() should return []
10. **Million events** - performance should be acceptable (<1s)

---

### 1.4 State Projections

**File**: `src/events/projections.py` (â‰¤100 lines)
- [ ] Implement `StateProjection` class

**PASSING CRITERIA**:
- âœ… rebuild_state() replays all events in order
- âœ… State matches last code_version from events
- âœ… Stale events (old version) are ignored
- âœ… All EventType transitions handled
- âœ… No events = empty state (not error)

**FAILING CRITERIA**:
- âŒ rebuild_state() misses events
- âŒ rebuild_state() replays in wrong order
- âŒ State includes data from stale events
- âŒ Unknown EventType causes crash
- âŒ Empty event list causes error

**EDGE CASES**:
1. **No events for task_id** - should return empty initialized state
2. **Out-of-order events** (by timestamp) - should use sequence_number
3. **Duplicate sequence numbers** - should detect and error
4. **Missing causation chain** - should handle gracefully
5. **BUG_REPORT for old version** - should ignore if code_version doesn't match
6. **CORRECTION_COMPLETED without CORRECTION_STARTED** - should handle
7. **Multiple CODE_GENERATED** - should keep latest version
8. **Event with invalid data structure** - should handle or validate
9. **Very long event chain** (10k events) - performance check (<5s)
10. **CODE_GENERATED with version < current** - should reject as stale

---

### 1.5 Event Ordering Utilities

**File**: `src/events/ordering.py` (â‰¤100 lines)
- [ ] Implement `EventOrdering` class

**PASSING CRITERIA**:
- âœ… is_report_valid_for_current_code() uses all 3 methods (version, clock, hash)
- âœ… Version mismatch â†’ False
- âœ… Clock causality (report before correction) â†’ False
- âœ… Hash mismatch â†’ False
- âœ… All checks pass â†’ True

**FAILING CRITERIA**:
- âŒ Only checks 1 or 2 of the 3 methods
- âŒ Version match + clock mismatch â†’ returns True (should be False)
- âŒ Hash missing in event â†’ crashes (should handle gracefully)

**EDGE CASES**:
1. **Report and correction same version, concurrent clocks** - should use hash
2. **Hash missing in both events** - should fall back to version+clock
3. **code_hash is None** - should handle gracefully
4. **Report version > correction version** - invalid state, should detect
5. **Correction without hash** - should handle
6. **Empty causation chain** - should handle
7. **Report with future timestamp** - should not affect ordering (use sequence)

### ğŸ§ª TEST GATE 1: Event Store Tests

**File**: `tests/test_event_store.py` (â‰¤100 lines)

```python
# Test 1: Sequential append
âœ… PASS: Events [1,2,3,4,5] have sequence_numbers [1,2,3,4,5]
âŒ FAIL: Any gap, duplicate, or out-of-order sequence

# Test 2: Concurrent append
âœ… PASS: 100 concurrent appends produce 100 unique sequences [1..100]
âŒ FAIL: Any collision, gap, or duplicate

# Test 3: Persistence
âœ… PASS: After append, file exists and is valid JSON
âœ… PASS: Load from file reproduces exact events
âŒ FAIL: File corrupt, missing, or events lost

# Test 4: Filtering
âœ… PASS: get_events("task-A") returns only task-A events
âœ… PASS: get_events("task-B", after_sequence=5) returns only seq > 5
âŒ FAIL: Wrong events returned, or missing events

# Test 5: Thread safety
âœ… PASS: 10 async tasks appending 10 events each = 100 total, all unique
âŒ FAIL: Race condition, lost events, or duplicate sequences
```

**File**: `tests/test_vector_clock.py` (â‰¤100 lines)

```python
# Test 1: Causality detection
âœ… PASS: {"p1":1} happens_before {"p1":2} â†’ True
âœ… PASS: {"p1":1} happens_before {"p1":1,"p2":1} â†’ True
âŒ FAIL: Returns False for clear causal relationship

# Test 2: Concurrency detection
âœ… PASS: {"p1":1} concurrent {"p2":1} â†’ True
âœ… PASS: {"p1":2,"p2":1} concurrent {"p1":1,"p2":2} â†’ True
âŒ FAIL: Returns False for clearly concurrent events

# Test 3: Merge correctness
âœ… PASS: merge({"p1":5},{"p1":3,"p2":1}) â†’ {"p1":5,"p2":1}
âŒ FAIL: Doesn't take max, or loses processes

# Test 4: Edge cases
âœ… PASS: {} concurrent {} â†’ True
âœ… PASS: {"p1":0} handled correctly
âŒ FAIL: Crash on empty clocks or zero values
```

**File**: `tests/test_projections.py` (â‰¤100 lines)

```python
# Test 1: State rebuild
âœ… PASS: Events [CODE_GEN(v1), CORRECTION(v2)] â†’ state.code_version=2
âŒ FAIL: Wrong version, or missing updates

# Test 2: Stale event filtering
âœ… PASS: BUG_REPORT(v1) after CORRECTION(v2) â†’ ignored in state
âŒ FAIL: Stale data included in state

# Test 3: All event type handling
âœ… PASS: Each of 18 EventTypes processes without error
âŒ FAIL: Unknown EventType causes crash

# Test 4: Empty events
âœ… PASS: rebuild_state([]) â†’ empty initialized state, no error
âŒ FAIL: Crashes or returns None
```

**Run Tests**:
```bash
pytest tests/test_event_store.py tests/test_vector_clock.py tests/test_projections.py -v --tb=short
```

â›” **STOP HERE IF ANY TEST FAILS** â›”

**Debug checklist if tests fail**:
- [ ] Check asyncio.Lock is acquired before all dict/list modifications
- [ ] Check sequence_number assignment happens inside lock
- [ ] Check file writes are atomic (write to temp, then rename)
- [ ] Check vector clock merge uses `max()` not `min()`
- [ ] Check happens_before uses `all()` and `any()` correctly

---

## Phase 2: Task Orchestration ğŸ¯

### 2.1 Priority System

**File**: `src/orchestrator/priority.py` (â‰¤100 lines)
- [ ] Define `TaskPriority` IntEnum
- [ ] Implement `TaskPriorityAssigner`

**PASSING CRITERIA**:
- âœ… Priority values are integers (0, 10, 20, 30, 40)
- âœ… CRITICAL < HIGH < MEDIUM < LOW < BACKGROUND
- âœ… assign_priority() maps event types correctly
- âœ… should_preempt() returns True only if â‰¥20 priority difference

**FAILING CRITERIA**:
- âŒ Priority comparison broken (HIGH > CRITICAL)
- âŒ assign_priority() returns wrong priority for event
- âŒ should_preempt() allows 10-point difference (should be 20)

**EDGE CASES**:
1. **Unknown EventType** - should default to BACKGROUND
2. **None event** - should handle gracefully
3. **Event without event_type field** - should handle
4. **Negative priority** - should reject
5. **Priority > 100** - should handle or reject

---

### 2.2 Task Orchestrator

**File**: `src/orchestrator/task_orchestrator.py` (â‰¤100 lines)
- [ ] Implement `TaskOrchestrator` class

**PASSING CRITERIA**:
- âœ… Queue accepts tasks until maxsize (100) reached
- âœ… 101st task blocks until queue has space
- âœ… Semaphore limits to max_concurrent (5) simultaneous tasks
- âœ… Priority ordering: CRITICAL tasks execute before BACKGROUND
- âœ… Workers process tasks from queue continuously
- âœ… Timeout cancels long-running tasks
- âœ… shutdown() cancels all pending and active tasks

**FAILING CRITERIA**:
- âŒ Queue accepts 101+ tasks without blocking
- âŒ More than max_concurrent tasks run simultaneously
- âŒ Lower priority task executes before higher priority
- âŒ Workers stop processing queue
- âŒ Timeout doesn't cancel task
- âŒ shutdown() leaves tasks running

**EDGE CASES**:
1. **submit_task() with queue full** - should block until space available
2. **Worker crash** - should restart worker or handle gracefully
3. **Task raises exception** - should log and continue, not crash worker
4. **Task with timeout=0** - should cancel immediately
5. **submit_task() during shutdown** - should reject new tasks
6. **Circular task dependencies** - should detect or handle
7. **Task that never yields** - should timeout
8. **1000 tasks submitted rapidly** - should handle (100 queued, rest block)
9. **get_queue_stats() during high load** - should not block
10. **Duplicate task_id** - should handle or reject

**CRITICAL INTEGRATION**: Must handle existing global StateManager without race conditions!

---

### 2.3 Backpressure Monitoring

**File**: `src/orchestrator/backpressure.py` (â‰¤100 lines)
- [ ] Implement `BackpressureMonitor` class

**PASSING CRITERIA**:
- âœ… Alerts when queue is 80% full
- âœ… CRITICAL alert when queue is 100% full
- âœ… No false positives (alerting when queue <80%)

**FAILING CRITERIA**:
- âŒ No alert when queue 90% full
- âŒ Alert spam (multiple alerts per second)
- âŒ Crash when queue stats unavailable

**EDGE CASES**:
1. **Queue oscillating at 79-81%** - should debounce alerts
2. **Rapid queue drain** - should clear alert quickly
3. **Multiple orchestrators** - each should monitor independently

### ğŸ§ª TEST GATE 2: Task Orchestration Tests

**File**: `tests/test_task_orchestrator.py` (â‰¤100 lines)

```python
# Test 1: Priority ordering
âœ… PASS: Submit [LOW, CRITICAL, HIGH] â†’ executes in order [CRITICAL, HIGH, LOW]
âŒ FAIL: Wrong execution order

# Test 2: Max concurrent limit
âœ… PASS: Start 10 long tasks â†’ max 5 run simultaneously
âŒ FAIL: 6+ tasks run simultaneously

# Test 3: Backpressure (bounded queue)
âœ… PASS: Submit 105 tasks â†’ first 100 queue, last 5 block
âœ… PASS: After 1 completes, blocked task enters queue
âŒ FAIL: All 105 tasks enter queue immediately

# Test 4: Worker pool
âœ… PASS: 3 workers continuously process queue
âœ… PASS: 1 worker crash â†’ other 2 continue
âŒ FAIL: Workers stop processing

# Test 5: Timeout enforcement
âœ… PASS: Task with timeout=1s running 2s â†’ cancelled at 1s
âŒ FAIL: Task runs beyond timeout

# Test 6: Graceful shutdown
âœ… PASS: shutdown() cancels 20 queued + 5 active tasks
âœ… PASS: All tasks receive CancelledError
âŒ FAIL: Tasks left running after shutdown
```

**File**: `tests/test_priority_assignment.py` (â‰¤100 lines)

```python
# Test 1: Priority mapping
âœ… PASS: USER_INTERVENTION â†’ CRITICAL (0)
âœ… PASS: CODE_GENERATION â†’ HIGH (10)
âœ… PASS: DEAD_CODE_ANALYSIS â†’ LOW (30)
âŒ FAIL: Wrong priority assigned

# Test 2: Preemption logic
âœ… PASS: CRITICAL (0) should_preempt MEDIUM (20) â†’ True
âœ… PASS: HIGH (10) should_preempt MEDIUM (20) â†’ False (only 10 diff)
âŒ FAIL: Preemption logic incorrect
```

**Run Tests**:
```bash
pytest tests/test_task_orchestrator.py tests/test_priority_assignment.py -v -s
```

â›” **STOP HERE IF ANY TEST FAILS** â›”

**Debug checklist**:
- [ ] Check PriorityQueue correctly orders by priority (lower = higher)
- [ ] Check Semaphore(5) enforces max concurrent
- [ ] Check asyncio.Queue(maxsize=100) blocks on 101st put()
- [ ] Check workers use `while True` loop
- [ ] Check timeout uses asyncio.wait_for()

---

## Phase 3: Context Management for Small LLMs ğŸ§ 

### 3.1 Context Manager

**File**: `src/context/context_manager.py` (â‰¤100 lines)
- [ ] Implement `ContextManager` class

**PASSING CRITERIA**:
- âœ… Token estimate within 20% of actual (chars/4 Â± 20%)
- âœ… Routes to larger model when >80% of context limit
- âœ… 4-layer context structure maintained
- âœ… Cached prompts reused (not regenerated)

**FAILING CRITERIA**:
- âŒ Token estimate off by >30%
- âŒ Context exceeds model limit (causes LLM error)
- âŒ Routing to larger model fails
- âŒ Cache misses when it should hit

**EDGE CASES**:
1. **Event with 50K chars** - should trigger model routing
2. **mistral:7b at 7.5K tokens** - should route to qwen3:8b
3. **qwen3:8b at 30K tokens** - should route to claude (or reject)
4. **Unicode/emoji heavy text** - token estimate should handle
5. **Empty event history** - should still build valid context
6. **Very long system prompt** (5K tokens) - should include in estimate
7. **Cache warm, then clear** - should regenerate correctly

---

### 3.2 Event Summarizer

**File**: `src/context/event_summarizer.py` (â‰¤100 lines)
- [ ] Implement `EventSummarizer` class

**PASSING CRITERIA**:
- âœ… Compression achieves â‰¥5x token reduction
- âœ… Summary includes key statistics (module count, iteration count)
- âœ… Recent events (last 5) kept in full detail
- âœ… Older events compressed to 1-line summaries

**FAILING CRITERIA**:
- âŒ Compression <3x (not effective enough)
- âŒ Summary missing critical info (current version, status)
- âŒ Recent events lost or corrupted

**EDGE CASES**:
1. **keep_recent=5 but only 3 events** - should keep all 3
2. **1000 old events** - compression should still be fast (<100ms)
3. **Events with large data fields** - should truncate data in compression
4. **No events** - should return minimal summary, not error

---

### 3.3 System Prompt Cache

**File**: `src/context/prompt_cache.py` (â‰¤100 lines)
- [ ] Implement `SystemPromptCache` class

**PASSING CRITERIA**:
- âœ… First call generates prompt (cache miss)
- âœ… Second call reuses prompt (cache hit)
- âœ… clear_cache() invalidates all entries
- âœ… Different event_types have different prompts

**FAILING CRITERIA**:
- âŒ Cache always misses (regenerates every time)
- âŒ Cache returns wrong prompt for event_type
- âŒ clear_cache() doesn't actually clear

**EDGE CASES**:
1. **Unknown event_type** - should generate generic prompt
2. **Cache with 100 entries** - should handle (no size limit)
3. **Prompt generation fails** - should retry or use fallback

---

### 3.4 Relevance Filter

**File**: `src/context/relevance_filter.py` (â‰¤100 lines)
- [ ] Implement `RelevanceFilter` class

**PASSING CRITERIA**:
- âœ… Returns â‰¤limit events
- âœ… Events in chronological order
- âœ… Filters by: same module, same version, causal chain
- âœ… Empty result if no relevant events

**FAILING CRITERIA**:
- âŒ Returns >limit events
- âŒ Events out of chronological order
- âŒ Includes irrelevant events (wrong module/version)

**EDGE CASES**:
1. **limit=10 but only 3 relevant events** - return 3
2. **All events irrelevant** - return []
3. **Causation chain broken** - should still return what's available
4. **Events from multiple tasks mixed** - should filter correctly

### ğŸ§ª TEST GATE 3: Context Management Tests

**File**: `tests/test_context_manager.py` (â‰¤100 lines)

```python
# Test 1: 4-layer context
âœ… PASS: Context has [system_prompt, state_summary, compressed_events, current_event]
âŒ FAIL: Missing layer or wrong order

# Test 2: Token estimation
âœ… PASS: 10K chars â†’ ~2500 tokens estimate (Â±20%)
âŒ FAIL: Estimate off by >30%

# Test 3: Model routing
âœ… PASS: mistral:7b at 7K tokens â†’ routes to qwen3:8b
âœ… PASS: qwen3:8b at 28K tokens â†’ routes to larger model
âŒ FAIL: Doesn't route, or routes at wrong threshold

# Test 4: Cache effectiveness
âœ… PASS: Same event_type called twice â†’ prompt identical, not regenerated
âŒ FAIL: Cache miss on second call
```

**File**: `tests/test_event_summarizer.py` (â‰¤100 lines)

```python
# Test 1: Compression ratio
âœ… PASS: 50 events (10K tokens) â†’ summary (1.5K tokens) = 6.6x compression
âŒ FAIL: Compression <3x

# Test 2: keep_recent
âœ… PASS: 20 events, keep_recent=5 â†’ 5 full + 15 compressed
âŒ FAIL: Wrong number kept full, or order wrong

# Test 3: Summary content
âœ… PASS: Summary includes module count, iteration count, current version
âŒ FAIL: Missing critical statistics
```

**File**: `tests/test_relevance_filter.py` (â‰¤100 lines)

```python
# Test 1: Limit enforcement
âœ… PASS: 100 events, limit=10 â†’ returns exactly 10
âŒ FAIL: Returns â‰ 10

# Test 2: Relevance filtering
âœ… PASS: 50 events, same module â†’ returns only same-module events
âŒ FAIL: Returns events from other modules

# Test 3: Chronological order
âœ… PASS: Events returned in sequence_number order
âŒ FAIL: Out of order
```

**Run Tests**:
```bash
pytest tests/test_context_manager.py tests/test_event_summarizer.py tests/test_relevance_filter.py -v
```

â›” **STOP HERE IF ANY TEST FAILS** â›”

---

## Phase 4: FastAPI + WebSocket Layer ğŸŒ

### 4.1 Pydantic Models

**File**: `src/api/models/requests.py` (â‰¤100 lines)
- [ ] Define `TaskRequest`, `InterventionRequest` models

**PASSING CRITERIA**:
- âœ… TaskRequest.prompt is non-empty string
- âœ… TaskRequest.answers is list (can be empty)
- âœ… Pydantic validation rejects invalid data

**FAILING CRITERIA**:
- âŒ Accepts empty prompt ""
- âŒ Accepts answers as non-list
- âŒ Validation doesn't catch malformed data

**EDGE CASES**:
1. **prompt with 100K chars** - should handle or reject with clear error
2. **answers with 1000 items** - should handle
3. **Unicode/emoji in prompt** - should handle
4. **priority="CRITICAL"** (string) - should convert to TaskPriority enum
5. **priority="INVALID"** - should reject with error

**File**: `src/api/models/responses.py` (â‰¤100 lines)
- [ ] Define response models

**PASSING CRITERIA**:
- âœ… All required fields present
- âœ… Serialization to JSON works
- âœ… websocket_url format is valid (ws://host:port/ws/task_id)

**FAILING CRITERIA**:
- âŒ Missing required fields
- âŒ Non-serializable fields
- âŒ Invalid URL format

**EDGE CASES**:
1. **task_id with special chars** - URL encoding should handle
2. **Very long task_id** (1000 chars) - should handle or reject
3. **None values** - should serialize as null

---

### 4.2 WebSocket Manager

**File**: `src/api/websocket_manager.py` (â‰¤100 lines)
- [ ] Implement `WebSocketManager` class

**PASSING CRITERIA**:
- âœ… connect() accepts WebSocket and stores in dict
- âœ… Multiple clients can connect to same task_id
- âœ… broadcast_to_task() sends to all connected clients
- âœ… disconnect() removes client and cleans up empty lists
- âœ… Failed sends don't crash other broadcasts

**FAILING CRITERIA**:
- âŒ Only 1 client per task_id allowed
- âŒ broadcast fails if one client disconnected
- âŒ Memory leak (disconnected clients not removed)

**EDGE CASES**:
1. **Client connects, then immediately disconnects** - should handle
2. **broadcast to task_id with no clients** - should be no-op, not error
3. **Client connection fails during accept** - should handle gracefully
4. **100 clients for same task_id** - should broadcast to all efficiently
5. **Client receives message, then disconnects** - no error
6. **WebSocket send raises exception** - should catch and remove client
7. **Concurrent connect/disconnect** - should be thread-safe

**CRITICAL**: Must integrate with existing `StreamingWorkflowOrchestrator`!

---

### 4.3 Task Manager (FastAPI Integration)

**File**: `src/api/task_manager.py` (â‰¤100 lines)
- [ ] Implement `TaskManager` class

**PASSING CRITERIA**:
- âœ… start_task() creates asyncio.Task and stores in dict
- âœ… Callback cleanup when task completes
- âœ… cancel_task() cancels and awaits task
- âœ… get_task_status() queries event store (not in-memory state)
- âœ… shutdown_all() cancels all tasks

**FAILING CRITERIA**:
- âŒ start_task() blocks until task completes
- âŒ Completed tasks not removed (memory leak)
- âŒ cancel_task() doesn't await (leaves zombie tasks)
- âŒ shutdown_all() misses some tasks

**EDGE CASES**:
1. **Task raises exception** - callback should still fire
2. **cancel_task() on completed task** - should handle gracefully
3. **Double cancel** - should be idempotent
4. **get_task_status() for unknown task_id** - should return error, not crash
5. **start_task() with duplicate task_id** - should reject or overwrite

**CRITICAL INTEGRATION**: Must work with existing `StateManager` global dict!

---

### 4.4-4.6 Endpoints

**Files**: `src/api/endpoints/*.py` (â‰¤100 lines each)
- [ ] health.py, tasks.py, websocket.py

**PASSING CRITERIA**:
- âœ… POST /tasks returns 200 with task_id
- âœ… GET /tasks/{task_id} returns current status
- âœ… WebSocket /ws/{task_id} accepts connection
- âœ… WebSocket receives versioned messages
- âœ… GET /health returns 200 when healthy

**FAILING CRITERIA**:
- âŒ POST /tasks with invalid data returns 200 (should be 400)
- âŒ GET /tasks/nonexistent returns 200 (should be 404)
- âŒ WebSocket doesn't send version in messages
- âŒ Health check returns 200 when Ollama down (should be 503)

**EDGE CASES**:
1. **POST /tasks during high load** - should queue or reject gracefully
2. **GET /tasks/{id} for task that hasn't started** - should return status "created"
3. **WebSocket connect before task starts** - should wait or error clearly
4. **WebSocket receives out-of-order messages** - client should sort by sequence
5. **Health check during DSPy reconfiguration** - should handle

---

### 4.7 Versioned State Manager

**File**: `src/api/versioned_state.py` (â‰¤100 lines)
- [ ] Implement `VersionedState` class

**PASSING CRITERIA**:
- âœ… update() rejects version â‰¤ current_version
- âœ… update() is thread-safe (asyncio.Lock)
- âœ… get_current_version() returns latest version
- âœ… States indexed by version number

**FAILING CRITERIA**:
- âŒ Accepts stale update (v2 after v3)
- âŒ Race condition on concurrent updates
- âŒ Version collision (two states with same version)

**EDGE CASES**:
1. **Update v1, v3 (skip v2)** - should accept (versions can have gaps)
2. **Concurrent update of v2 from two sources** - only one should succeed
3. **Update with v=0** - should accept as initial
4. **get_current_version() with no updates** - should return 0
5. **Very large version number** (2^31) - should handle

### ğŸ§ª TEST GATE 4: FastAPI Tests

**File**: `tests/test_api_models.py` (â‰¤100 lines)

```python
# Test 1: Pydantic validation
âœ… PASS: TaskRequest(prompt="test") â†’ valid
âŒ FAIL: TaskRequest(prompt="") â†’ ValidationError not raised

# Test 2: Serialization
âœ… PASS: TaskResponse(...).dict() â†’ valid JSON dict
âŒ FAIL: Non-serializable fields cause error
```

**File**: `tests/test_websocket_manager.py` (â‰¤100 lines)

```python
# Test 1: Multiple clients
âœ… PASS: 3 clients connect to task-A â†’ all 3 receive broadcast
âŒ FAIL: Only 1 receives, or broadcast fails

# Test 2: Cleanup
âœ… PASS: Client disconnects â†’ removed from active_connections
âŒ FAIL: Client lingers (memory leak)

# Test 3: Failed send
âœ… PASS: 1 of 3 clients fails â†’ other 2 still receive message
âŒ FAIL: All broadcasts fail due to 1 bad client
```

**File**: `tests/test_task_manager.py` (â‰¤100 lines)

```python
# Test 1: Task creation
âœ… PASS: start_task() creates asyncio.Task
âœ… PASS: Task ID in active_tasks dict
âŒ FAIL: Task not tracked

# Test 2: Cancellation
âœ… PASS: cancel_task() cancels and removes from dict
âŒ FAIL: Task still running, or not removed

# Test 3: Callback cleanup
âœ… PASS: Task completes â†’ callback fires â†’ removed from dict
âŒ FAIL: Callback doesn't fire, task lingers
```

**File**: `tests/test_endpoints.py` (â‰¤100 lines)

```python
# Test 1: POST /tasks
âœ… PASS: Valid request â†’ 200, returns task_id
âŒ FAIL: Invalid request â†’ 200 (should be 400)

# Test 2: GET /tasks/{id}
âœ… PASS: Existing task â†’ 200, returns status
âœ… PASS: Nonexistent task â†’ 404
âŒ FAIL: 404 returns 200, or 200 returns 500

# Test 3: GET /health
âœ… PASS: DSPy configured, Ollama reachable â†’ 200
âŒ FAIL: Returns 200 when Ollama down
```

**File**: `tests/test_websocket_endpoint.py` (â‰¤100 lines)

```python
# Test 1: Connection
âœ… PASS: WS /ws/task-A connects successfully
âŒ FAIL: Connection refused or timeout

# Test 2: Message versioning
âœ… PASS: All messages include version and sequence fields
âŒ FAIL: Missing version or sequence

# Test 3: Stale update rejection
âœ… PASS: Client at v3 receives v2 message â†’ ignores
âŒ FAIL: Client processes stale message
```

**Run Tests**:
```bash
pytest tests/test_api_models.py tests/test_websocket_manager.py tests/test_task_manager.py tests/test_endpoints.py tests/test_websocket_endpoint.py -v
```

â›” **STOP HERE IF ANY TEST FAILS** â›”

---

## Phase 5: Hybrid FastAPI + FastMCP Main App ğŸ”—

### 5.1 Main FastAPI App

**File**: `src/api/main.py` (â‰¤100 lines)

**PASSING CRITERIA**:
- âœ… Lifespan startup configures DSPy successfully
- âœ… Orchestrator workers start (3 workers running)
- âœ… All routers mounted (/health, /tasks, /ws)
- âœ… FastMCP mounted at /mcp/
- âœ… app.state contains all managers
- âœ… Lifespan shutdown cancels all tasks

**FAILING CRITERIA**:
- âŒ DSPy configuration fails, app still starts
- âŒ Workers don't start
- âŒ FastMCP not accessible at /mcp/
- âŒ Shutdown doesn't clean up tasks

**EDGE CASES**:
1. **Ollama not running at startup** - should error clearly, not start
2. **Port 9876 already in use** - should error clearly
3. **Shutdown during active task** - should wait for cancellation
4. **Restart after crash** - should reinitialize cleanly

---

### 5.2 Modify Existing MCP Server

**File**: `src/mcp/fastmcp_server.py` (MODIFY)

**CHANGES**:
```python
# Add at end (line 151+):
def get_asgi_app():
    """Export FastMCP as ASGI app for mounting"""
    return mcp.get_asgi_app()
```

**PASSING CRITERIA**:
- âœ… get_asgi_app() returns valid ASGI app
- âœ… All existing tools still work via stdio
- âœ… Mounted app works via HTTP at /mcp/

**FAILING CRITERIA**:
- âŒ get_asgi_app() returns None or errors
- âŒ stdio mode broken
- âŒ HTTP mode broken

**EDGE CASES**:
1. **stdio and HTTP used simultaneously** - should work independently
2. **global state shared** - should be thread-safe

---

### 5.3 Update Server Runner

**File**: `src/mcp/server_runner.py` (MODIFY)

**CHANGES**:
- Add --fastapi flag
- If --fastapi: `subprocess.run(["uvicorn", "src.api.main:app", ...])`

**PASSING CRITERIA**:
- âœ… --fastapi starts hybrid server on port 9876
- âœ… --http still works (FastMCP HTTP only)
- âœ… Default (no flags) still works (stdio)

**FAILING CRITERIA**:
- âŒ --fastapi doesn't start server
- âŒ Breaking existing modes

### ğŸ§ª TEST GATE 5: Integration Tests

**File**: `tests/test_hybrid_integration.py` (â‰¤100 lines)

```python
# Test 1: FastAPI endpoints work
âœ… PASS: POST /tasks returns 200
âŒ FAIL: 404 or 500

# Test 2: FastMCP tools work
âœ… PASS: POST /mcp/tools/call â†’ start_coding_task works
âŒ FAIL: 404 or tool doesn't execute

# Test 3: Shared state
âœ… PASS: Task created via REST visible via MCP get_task_status
âŒ FAIL: State not shared

# Test 4: Lifespan
âœ… PASS: Startup configures DSPy, logs confirm
âœ… PASS: Shutdown cancels tasks, logs confirm
âŒ FAIL: Startup/shutdown errors
```

**File**: `tests/test_network_access.py` (â‰¤100 lines)

```python
# Test 1: 0.0.0.0 binding
âœ… PASS: Server binds to 0.0.0.0:9876
âœ… PASS: Accessible from 127.0.0.1
âŒ FAIL: Only localhost, or port conflict

# Test 2: WebSocket from network
âœ… PASS: WS connection from external IP works
âŒ FAIL: Connection refused

# Test 3: MCP endpoint
âœ… PASS: http://localhost:9876/mcp/ returns MCP info
âŒ FAIL: 404 or error
```

**Run Tests**:
```bash
pytest tests/test_hybrid_integration.py tests/test_network_access.py -v
```

â›” **STOP HERE IF ANY TEST FAILS** â›”

---

## Phase 6: Workflow Integration ğŸ”„

### 6.1 Modify Workflow Orchestrator

**File**: `src/orchestrator/workflow.py` (MODIFY)

**CRITICAL INTEGRATION NOTES**:
- Existing WorkflowOrchestrator (line 30-166)
- Existing StreamingWorkflowOrchestrator (in streaming.py)
- Must add event emission WITHOUT breaking existing functionality

**PASSING CRITERIA**:
- âœ… Existing workflow still works without WebSocket manager
- âœ… With WebSocket manager, events emitted at each stage
- âœ… Events stored in EventStore
- âœ… Backward compatible (Optional parameters)

**FAILING CRITERIA**:
- âŒ Workflow breaks if event_store=None
- âŒ Events not emitted
- âŒ EventStore not populated

**EDGE CASES**:
1. **websocket_manager=None** - should work (for backward compat)
2. **event_store=None** - should work (for backward compat)
3. **Both provided** - should emit events to both
4. **WebSocket broadcast fails** - should continue workflow
5. **EventStore append fails** - should log error, continue workflow

**INTEGRATION WITH EXISTING EVENT SYSTEM**:
- Existing `WorkflowEvent` in orchestrator/events.py
- New `Event` in events/event.py
- Must coexist! Perhaps emit both temporarily.

---

### 6.2 Modify State Manager

**File**: `src/orchestrator/state.py` (MODIFY)

**CHANGES**:
```python
# Line 23+ in TaskState.__init__:
self.asyncio_task: Optional[asyncio.Task] = None
self.websocket_connections: List[WebSocket] = []
self.code_version: int = 0
```

**PASSING CRITERIA**:
- âœ… New fields added
- âœ… Existing fields unchanged
- âœ… Backward compatible (old code still works)

**FAILING CRITERIA**:
- âŒ Breaking changes to existing fields
- âŒ Import errors

**CRITICAL**: StateManager uses dict, NOT thread-safe! Must add locks or use async-safe structure.

### ğŸ§ª TEST GATE 6: Workflow Integration Tests

**File**: `tests/test_workflow_events.py` (â‰¤100 lines)

```python
# Test 1: Event emission
âœ… PASS: Workflow emits TASK_STARTED, PLANNING_COMPLETE, MODULE_STARTED, etc.
âŒ FAIL: Events missing or out of order

# Test 2: Version increment
âœ… PASS: CODE_GENERATED events have version [1,2,3...]
âŒ FAIL: Version doesn't increment, or skips numbers

# Test 3: WebSocket broadcast
âœ… PASS: Connected client receives all events
âŒ FAIL: Client misses events

# Test 4: EventStore population
âœ… PASS: EventStore contains all workflow events after completion
âŒ FAIL: Events missing or corrupted
```

**File**: `tests/test_end_to_end.py` (â‰¤100 lines)

```python
# Test 1: Full workflow
âœ… PASS: POST /tasks â†’ workflow completes â†’ GET /tasks/{id} shows "completed"
âŒ FAIL: Workflow hangs, errors, or status wrong

# Test 2: WebSocket receives all events
âœ… PASS: Client receives [TASK_STARTED ... TASK_COMPLETE] in order
âŒ FAIL: Events out of order, or missing

# Test 3: Version monotonicity
âœ… PASS: All events have increasing version numbers
âŒ FAIL: Version decreases or repeats

# Test 4: Event history
âœ… PASS: EventStore.get_events(task_id) returns complete history
âŒ FAIL: History incomplete

# Test 5: Context manager used
âœ… PASS: DSPy calls use context from ContextManager
âŒ FAIL: Context not used, or exceeds model limits
```

**Run Tests**:
```bash
pytest tests/test_workflow_events.py tests/test_end_to_end.py -v --tb=long
```

â›” **STOP HERE IF ANY TEST FAILS** â›”

---

## Summary: Critical Edge Cases Across All Phases

### Thread Safety Issues (HIGH PRIORITY):
1. StateManager.tasks - concurrent access
2. InterventionManager.interventions - concurrent access
3. EventStore.sequence_counter - must use lock
4. AsyncLogger.logs - list append not atomic
5. WebSocketManager.active_connections - dict modification

### Data Validation Issues:
6. task_id - never validated (could be empty, None, malicious)
7. prompt - could be empty string ""
8. code_version - could be negative
9. event.data - could contain non-serializable objects
10. module_spec.dependencies - could be malformed

### Integration Gotchas:
11. Two event systems (WorkflowEvent vs Event) - must coexist
12. StreamingWorkflowOrchestrator already exists - must integrate
13. Global state managers - must be made async-safe
14. TestRunner subprocess.run - blocks event loop, not truly async
15. AsyncLogger file writes - not atomic, race condition

### Performance Edge Cases:
16. 1M events in EventStore - projection should be <5s
17. 100 concurrent WebSocket clients - broadcast should be <100ms
18. Queue with 100 tasks - submit should block, not error
19. Very long context (50K tokens) - should route to larger model
20. 1000 task_ids in StateManager - lookup should be O(1)

### Error Handling:
21. Ollama not running - should fail fast with clear error
22. Disk full during event persist - should handle gracefully
23. WebSocket client disconnects mid-broadcast - should continue
24. DSPy returns malformed result - should validate and retry
25. Test timeout during high load - should cancel gracefully

---

## Final Pre-Implementation Checklist

Before starting Phase 1:
- [ ] Read this entire document
- [ ] Understand all edge cases
- [ ] Understand integration with existing code (events.py, streaming.py, state.py)
- [ ] Have pytest installed and working
- [ ] Have uvicorn installed (pip install uvicorn[standard])
- [ ] Ollama running (http://localhost:11434)
- [ ] Test existing workflow works (python -m src.mcp.server_runner)

**Current Status**: â¸ï¸ Awaiting user approval and write access to `src/`
