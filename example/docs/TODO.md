# AI ReAct Agent Pipeline Bug Fixes for Intelligent Chatbot - DETAILED TODO

## Project: @example/** - DSPy-powered WhatsApp Chatbot

## Executive Summary

**Project**: Intelligent Car Wash Chatbot with DSPy
**Objective**: Fix critical issues identified in BUGS_2.md where regex-based extraction was prioritized over DSPy modules, causing extraction failure and performance degradation
**Target**: Restore core functionality while maintaining enhanced validation and hybrid intent analysis

## Architecture Context

Based on the system architecture documented in `@example/architecture.md`:

```bash
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                WhatsApp User                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              pyWA (WhatsApp API)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Your Existing Rule-Based Chatbot            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Intelligence Layer (This System)           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   ChatbotOrchestrator (Main Coordinator)    ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ             ‚îÇ                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚ñº                       ‚ñº                   ‚ñº      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Sentiment   ‚îÇ  ‚îÇ     Data      ‚îÇ ‚îÇ  Conv.  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Analyzer    ‚îÇ  ‚îÇ  Extractor    ‚îÇ ‚îÇ Manager ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ         ‚îÇ                  ‚îÇ                ‚îÇ       ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                    ‚ñº                                ‚îÇ
‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ
‚îÇ         ‚îÇ   DSPy + Ollama LLM  ‚îÇ                    ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Core Issues to Address

### 1. Data Extraction Problem

- **Current Issue**: Regex-first approach in `@example/data_extractor.py` bypasses DSPy modules causing extraction failure
- **Impact**: No extraction results being captured ("üì¶ EXTRACTED: None")
- **Root Cause**: Implementation prioritizes regex over sophisticated DSPy extraction modules

### 2. Validation Blocking LLM Outputs

- **Current Issue**: Strict validation in `@example/models.py` rejects valid LLM outputs
- **Impact**: Data extraction and sentiment analysis partially failing
- **Root Cause**: Overly restrictive validation preventing proper LLM result processing

### 3. Performance Degradation

- **Current Issue**: Extreme latencies (186+ seconds) due to multiple LLM calls and validation overhead
- **Impact**: Poor user experience with extremely slow responses
- **Root Cause**: Multiple LLM calls per turn and inefficient processing flow

### 4. Architectural Inconsistency

- **Current Issue**: Implementation deviates from DSPy-first approach
- **Impact**: Underutilization of sophisticated DSPy modules and signatures
- **Root Cause**: Prioritizing simple regex patterns over Chain-of-Thought reasoning

## Solution Architecture

### A. Overview

The solution will restore proper DSPy-first architecture while maintaining the validation improvements and hybrid intent analysis already implemented, focusing on fixing the core extraction issues.

### B. Key Components

1. **Restore DSPy-First Extraction**: Switch from regex-first to DSPy-first extraction
2. **Fix Validation Blocking**: Adjust validation to be permissive rather than restrictive
3. **Optimize Performance**: Reduce redundant LLM calls and processing overhead
4. **Maintain New Features**: Keep enhanced validation models and hybrid intent analysis
5. **Proper Integration**: Ensure DSPy modules integrate correctly with validation models

## Phase 1: Restore DSPy-First Data Extraction

### 1.1 Implementation Steps

#### File: `@example/data_extractor.py`

**Task**: Switch from regex-first to DSPy-first extraction approach

- [ ] Modify `extract_name` method to:
  - [ ] Try DSPy `NameExtractor` first as primary extraction method
  - [ ] Use regex pattern matching only as fallback when DSPy fails
  - [ ] Pass DSPy results through `ValidatedName` model validation
  - [ ] Add proper error handling when validation rejects DSPy results
  - [ ] Ensure regex fallback returns compatible format for validation models
- [ ] Modify `extract_vehicle_details` method to:
  - [ ] Try DSPy `VehicleDetailsExtractor` first as primary extraction method
  - [ ] Use regex pattern matching only as fallback when DSPy fails
  - [ ] Pass DSPy results through `ValidatedVehicleDetails` model validation
  - [ ] Add proper error handling when validation rejects DSPy results
- [ ] Modify `parse_date` method to:
  - [ ] Try DSPy `DateParser` first as primary extraction method
  - [ ] Use regex pattern matching only as fallback when DSPy fails
  - [ ] Pass DSPy results through `ValidatedDate` model validation
  - [ ] Add proper error handling when validation rejects DSPy results

#### File: `@example/models.py`

**Task**: Adjust strict validation rules that block valid LLM outputs

- [ ] Modify `ValidatedName.validate_name_consistency` to be more permissive
  - [ ] Allow partial matches between first name/last name and full name
  - [ ] Add normalization to format names consistently before validation
  - [ ] Return warnings instead of errors when possible
- [ ] Modify `ValidatedVehicleDetails.validate_vehicle_details` to be more permissive
  - [ ] Adjust number plate validation to be less restrictive
  - [ ] Allow broader brand name formats
  - [ ] Allow shorter brand names than current minimum
- [ ] Review all validation methods to ensure they support LLM output formats

#### File: `@example/modules.py`

**Task**: Ensure DSPy modules are properly utilized

- [ ] Verify `NameExtractor`, `VehicleDetailsExtractor`, and `DateParser` are fully functional
- [ ] Add error handling around DSPy module calls
- [ ] Ensure modules return properly formatted outputs for validation models

### 1.2 Quantitative Criteria

#### PASSING CRITERIA

- ‚úÖ DSPy extraction success rate > 85% for all extraction types
- ‚úÖ Regex fallback usage < 15% of total extractions 
- ‚úÖ Data extraction results captured in > 70% of conversation turns
- ‚úÖ Validation blocking rate < 5% (95% of LLM outputs pass validation)
- ‚úÖ Individual extraction time < 5 seconds for DSPy methods

#### ACCEPTED FAILING CRITERIA

- ‚ö†Ô∏è DSPy extraction success rate 75-85% for complex inputs
- ‚ö†Ô∏è Regex fallback usage 15-25% for rare edge cases
- ‚ö†Ô∏è Validation blocking rate 5-10% for unusual LLM outputs

#### UNACCEPTABLE FAILING CRITERIA

- ‚ùå DSPy extraction success rate < 70%
- ‚ùå Regex fallback required > 30% of the time
- ‚ùå Data extraction results in < 30% of conversation turns
- ‚ùå Validation blocking rate > 20% of LLM outputs
- ‚ùå Individual extraction time > 10 seconds during normal operation

### 1.3 Edge Cases

- [ ] LLM outputs with unexpected format or structure
- [ ] Partial extraction results from LLM (missing fields)
- [ ] Very long or very short text inputs
- [ ] Special characters or Unicode in inputs
- [ ] LLM confidence in low/medium range
- [ ] Validation model receiving malformed data
- [ ] Multiple attempts to extract same data type

### 1.4 Implementation Solutions for Edge Cases

- [ ] Implement result normalization between LLM and validation models
- [ ] Add graceful handling of partial results with optional fields
- [ ] Add input sanitization for special characters
- [ ] Implement confidence-based processing thresholds
- [ ] Add model result validation before passing to Pydantic models
- [ ] Implement retry logic with different extraction approaches

## Phase 2: Address Validation Blocking Issues

### 2.1 Implementation Steps

#### File: `@example/models.py`

**Task**: Adjust validation strictness to prevent blocking valid results

- [ ] Modify `ValidatedName` validation:
  - [ ] Relax `validate_name_consistency` to allow near-matches
  - [ ] Adjust `validate_name_format` to handle LLM-specific output variations
  - [ ] Add normalization methods to format LLM output for validation
- [ ] Modify `ValidatedVehicleDetails` validation:
  - [ ] Adjust number plate validation to accept common LLM variations
  - [ ] Allow brand names from both enum and string formats
  - [ ] Reduce strictness of plate format validation
- [ ] Modify `ValidatedDate` validation:
  - [ ] Adjust date range validation to be more permissive
  - [ ] Add normalization for date string formats
  - [ ] Allow broader acceptable date ranges

#### File: `@example/data_extractor.py`

**Task**: Add result normalization between LLM output and validation models

- [ ] Add `normalize_name_result` function to format LLM name output for validation
  - [ ] Properly capitalize names
  - [ ] Ensure first name and full name consistency
  - [ ] Handle missing last name appropriately
- [ ] Add `normalize_vehicle_result` function to format LLM vehicle output for validation
  - [ ] Normalize number plate format
  - [ ] Standardize brand name format
  - [ ] Validate model name format
- [ ] Add `normalize_date_result` function to format LLM date output for validation
  - [ ] Ensure proper date format
  - [ ] Validate date reasonableness
  - [ ] Standardize confidence values

#### File: `@example/sentiment_analyzer.py`

**Task**: Fix sentiment analysis validation blocking

- [ ] Add normalization to `_parse_score` to ensure 1-10 range compliance
- [ ] Reduce strictness of score validation in `ValidatedSentimentScores`
- [ ] Add fallback values when validation fails

### 2.2 Quantitative Criteria

#### PASSING CRITERIA

- ‚úÖ Validation blocking rate < 5% across all models
- ‚úÖ LLM output success rate > 95% (after normalization)
- ‚úÖ Average validation time < 0.1 seconds per extraction
- ‚úÖ Correctly formatted results > 90% of the time
- ‚úÖ False validation errors < 2% of all validation attempts

#### ACCEPTED FAILING CRITERIA

- ‚ö†Ô∏è Validation blocking rate 5-10% for unusual inputs
- ‚ö†Ô∏è LLM output success rate 90-95% after normalization
- ‚ö†Ô∏è Validation time 0.1-0.2 seconds occasionally

#### UNACCEPTABLE FAILING CRITERIA

- ‚ùå Validation blocking rate > 20%
- ‚ùå LLM output success rate < 85%
- ‚ùå Validation time > 0.5 seconds
- ‚ùå False validation errors > 10% of attempts
- ‚ùå System crashes due to validation errors

### 2.3 Edge Cases

- [ ] LLM outputs with out-of-range values
- [ ] LLM outputs with unexpected data types
- [ ] Partial results with missing fields
- [ ] Multiple errors in a single validation
- [ ] Validation model receiving None or null values
- [ ] Extremely long strings that exceed field limits
- [ ] Special characters that fail pattern validation

### 2.4 Implementation Solutions for Edge Cases

- [ ] Implement range clamping for numeric values
- [ ] Add type conversion for unexpected data types
- [ ] Allow optional fields in validation models
- [ ] Add detailed error reporting for debugging
- [ ] Implement null/None value handling
- [ ] Add string length truncation with warnings
- [ ] Add character sanitization for pattern validation

## Phase 3: Performance Optimization

### 3.1 Implementation Steps

#### File: `@example/data_extractor.py`

**Task**: Optimize extraction process to reduce redundant LLM calls

- [ ] Implement result caching for repeated extractions
  - [ ] Add LRU cache for recent extraction results
  - [ ] Add cache invalidation based on time or context changes
- [ ] Combine multiple extractions when possible
  - [ ] Add method to extract all data types in single LLM call
  - [ ] Add batch processing for multiple related extractions
- [ ] Add intelligent extraction skipping
  - [ ] Skip extraction when not relevant to current state
  - [ ] Add context-based extraction requirements

#### File: `@example/chatbot_orchestrator.py`

**Task**: Optimize orchestrator process for better performance

- [ ] Implement parallel processing for independent tasks
  - [ ] Extract data and analyze sentiment simultaneously
  - [ ] Run multiple independent validations in parallel
- [ ] Optimize state management and history retrieval
  - [ ] Cache conversation history when possible
  - [ ] Optimize history slicing operations
- [ ] Add early exit conditions when possible
  - [ ] Skip processing when confidence is too low
  - [ ] Reduce processing for simple conversation states

#### File: `@example/conversation_manager.py`

**Task**: Optimize context management for better performance

- [ ] Add caching for frequently accessed conversation data
- [ ] Optimize history retrieval methods
- [ ] Add lazy loading for conversation context components

### 3.2 Quantitative Criteria

#### PASSING CRITERIA

- ‚úÖ Average response time < 5 seconds for typical interactions
- ‚úÖ Maximum response time < 15 seconds for complex interactions
- ‚úÖ 50% reduction in redundant LLM calls
- ‚úÖ Cache hit rate > 60% for repeated operations
- ‚úÖ No performance degradation in data extraction accuracy

#### ACCEPTED FAILING CRITERIA

- ‚ö†Ô∏è Average response time 5-8 seconds during peak usage
- ‚ö†Ô∏è Maximum response time 15-20 seconds for very complex cases
- ‚ö†Ô∏è Cache hit rate 50-60% for repeated operations

#### UNACCEPTABLE FAILING CRITERIA

- ‚ùå Average response time > 15 seconds during normal operation
- ‚ùå Maximum response time > 30 seconds
- ‚ùå Performance degradation > 20% in extraction accuracy
- ‚ùå System instability due to caching issues
- ‚ùå Race conditions in parallel processing

### 3.3 Edge Cases

- [ ] High concurrent usage scenarios
- [ ] Cache memory overflow situations
- [ ] Parallel processing conflicts
- [ ] Invalid cache entries
- [ ] System memory constraints
- [ ] Network timeouts during LLM calls
- [ ] Cache synchronization issues

### 3.4 Implementation Solutions for Edge Cases

- [ ] Implement cache size limits with LRU eviction
- [ ] Add timeout handling for LLM calls
- [ ] Add thread-safe caching mechanisms
- [ ] Implement cache validation and refresh
- [ ] Add memory usage monitoring
- [ ] Create fallback mechanisms when caching fails
- [ ] Add proper synchronization for parallel operations

## Phase 4: Maintain New Features

### 4.1 Implementation Steps

#### File: `@example/chatbot_orchestrator.py`

**Task**: Preserve enhanced hybrid intent analysis while fixing extraction

- [ ] Maintain `detect_intent_keyword_based` and `detect_intent_llm_based` methods
- [ ] Preserve intent disagreement resolution logic
- [ ] Maintain correction detection functionality
- [ ] Ensure hybrid intent analysis works with optimized extraction flow
- [ ] Add proper error handling for intent detection failures

#### File: `@example/models.py`

**Task**: Preserve enhanced validation models while fixing blocking issues

- [ ] Maintain `ValidationResult` and `ExtractionMetadata` models
- [ ] Preserve validation pipeline and confidence thresholds
- [ ] Keep privacy compliance and data filtering configurations
- [ ] Maintain feedback mechanism integration
- [ ] Ensure all validation results are properly tracked

#### File: `@example/conversation_manager.py`

**Task**: Ensure conversation management works with new extraction improvements

- [ ] Verify `ValidatedConversationContext` works with optimized flow
- [ ] Maintain conversation history management functionality
- [ ] Preserve state transition tracking
- [ ] Ensure user data storage remains functional

### 4.2 Quantitative Criteria

#### PASSING CRITERIA

- ‚úÖ Hybrid intent analysis accuracy > 85% maintained
- ‚úÖ All validation model features remain functional
- ‚úÖ Conversation management performance improvement > 30%
- ‚úÖ No regression in existing feature functionality
- ‚úÖ Enhanced feedback mechanisms continue to operate

#### ACCEPTED FAILING CRITERIA

- ‚ö†Ô∏è Intent analysis accuracy 80-85% maintained
- ‚ö†Ô∏è Minor performance impact (<10%) on other features

#### UNACCEPTABLE FAILING CRITERIA

- ‚ùå Intent analysis accuracy < 75%
- ‚ùå Loss of any enhanced validation features
- ‚ùå Regression > 20% in existing feature performance
- ‚ùå Breakage of feedback collection mechanisms
- ‚ùå Invalid conversation state management

### 4.3 Edge Cases

- [ ] Intent disagreement resolution fails
- [ ] Validation metadata not properly populated
- [ ] Conversation history corruption
- [ ] State transition tracking fails
- [ ] Feedback collection mechanism errors
- [ ] Privacy filtering conflicts with extraction
- [ ] Multiple features accessing data simultaneously

### 4.4 Implementation Solutions for Edge Cases

- [ ] Add fallback intent classification when hybrid fails
- [ ] Create default validation metadata when values are missing
- [ ] Implement conversation history validation and recovery
- [ ] Add state transition validation and error correction
- [ ] Implement robust feedback collection error handling
- [ ] Create conflict resolution between features
- [ ] Add comprehensive locking for concurrent access

## Phase 5: Testing and Validation

### 5.1 Implementation Steps

#### File: `@example/test_example.py`

**Task**: Add comprehensive tests for fixed extraction functionality

- [ ] Add tests for DSPy-first extraction flow
- [ ] Create tests for validation normalization
- [ ] Add performance tests to ensure optimizations work
- [ ] Create tests for error handling and fallbacks
- [ ] Add tests for preserved new features

#### File: `@example/conversation_simulator.py`

**Task**: Update simulator to test fixed extraction flow

- [ ] Add scenarios that test DSPy extraction success
- [ ] Include validation blocking test scenarios
- [ ] Add performance measurement scenarios
- [ ] Include edge case testing for new fixes
- [ ] Verify preserved features continue to work

#### File: `@example/test_api.py`

**Task**: Enhance API tests for performance and correctness

- [ ] Add latency tracking for fixed implementation
- [ ] Test extraction success rates through API
- [ ] Add stress tests for performance improvements
- [ ] Include validation failure and recovery testing
- [ ] Verify all API endpoints work with new architecture

### 5.2 Quantitative Criteria

#### PASSING CRITERIA

- ‚úÖ All unit tests pass (>95% success rate)
- ‚úÖ Integration tests pass (>90% success rate)
- ‚úÖ Extraction success rate > 85% in simulator tests
- ‚úÖ Performance improvement validated (>50% latency reduction)
- ‚úÖ No regression in existing functionality

#### ACCEPTED FAILING CRITERIA

- ‚ö†Ô∏è Unit test success rate 90-95%
- ‚ö†Ô∏è Integration test success rate 85-90%
- ‚ö†Ô∏è Performance improvement 30-50% latency reduction

#### UNACCEPTABLE FAILING CRITERIA

- ‚ùå Unit test success rate < 90%
- ‚ùå Integration test success rate < 85%
- ‚ùå Performance regression (worse than original)
- ‚ùå Existing functionality regression > 10%
- ‚ùå System instability during testing

### 5.3 Edge Cases

- [ ] Test suite fails due to updated architecture
- [ ] Performance tests fail under load
- [ ] API tests timeout due to changes
- [ ] Integration tests conflict with each other
- [ ] Test data not compatible with new validation
- [ ] Simulator scenarios don't reflect fixes
- [ ] Metrics not properly captured

### 5.4 Implementation Solutions for Edge Cases

- [ ] Update all tests to match new architecture
- [ ] Add load testing scenarios to API tests
- [ ] Implement proper test timeouts and error handling
- [ ] Add test isolation mechanisms
- [ ] Update test data to match new validation requirements
- [ ] Create relevant simulator scenarios for fixed issues
- [ ] Implement comprehensive metrics collection